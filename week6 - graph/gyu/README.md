# 인접 행렬과 인접 리스트
1. 인접 행렬은 O(N^2)의 공간을 필요로 하지만, 검색에 O(1)시간이 들고 구현이 간단하다.
2. 단, 인접 행렬은 sparse 행렬(희소 행렬)이므로 빈 공간이 많아 메모리 낭비가 크다.
3. 인접 리스트는 O(N^2)의 공간을 필요로 하지만, 빈 공간이 없어 메모리 효율이 좋다.
4. 검색에 O(N)이 걸릴 수 있고, 구현이 조금 더 까다롭다.

## 그래프 탐색
1. DFS: 더 이상 탐색할 노드가 없을 때까지 일단 가본다. 그러다가 더 이상 탐색할 노드가 없으면 최근에 방문했던 노드로 되돌아간 다음 가지 않은 노드를 방문한다. 
2. BFS: 현재 위치에서 가장 가까운 노드부터 모두 방문하고 다음 노드로 넘어간다. 그 노드에서 또 다시 가장 가까운 노드부터 모두 방문한다. 

### DFS
`stack`과 `재귀` 두 가지 버전이 존재한다.

- stack
1. stack에 시작 노드를 넣는다.
2. stack에서 노드 하나를 꺼내어, 방문했는 지 확인한다. 방문했다면 다음 stack을 팝하고, 방문 안했다면 방문 처리를 해준다음 넘어간다. **중요한 것은 stack에 넣을 때 방문처리를 하는 것이 아니라, stack에서 꺼낼 때 방문 처리를 한다.**
3. 방문한 노드와 인접한 모든 노드를 stack에 넣고, 1을 반복한다. 
4. stack이 비어있다면 종료한다.

- 재귀함수
dfs(n): n번 노드를 방문 처리하고, n번 노드와 인접한 노드 중 아직 방문하지 않은 노드를 탐색
1. dfs(start)로 시작하여 start 노드를 방문처리 
2. start 노드에 연결된 노드 중 하나를 dfs(next)로 방문
3. 방문한 노드는 가지않는다.

재밌는 차이는 stack의 경우 방문했는 지 안했는 지 처리를 stack에서 꺼낼 때 한다.
```py
def dfs_stack(n, start, graph):
    visited = [False for _ in range(n + 1)]
    stack = [start]
    
    while stack:
        cur = stack.pop()
        if visited[cur]:
            continue
        
        print(cur, end=" ")
        visited[cur] = True
        
        for node in graph[cur]:
            stack.append(node)
```

반면에 재귀의 경우는 재귀 함수를 실행할 때 넣는다.
```py
def dfs_recursive(n, cur, visited, graph):
    visited[cur] = True
    print(cur, end=" ")
    for node in graph[cur]:
        if visited[node]:
            continue
        dfs_recursive(n, node, visited, graph)
```

이 두 함수의 `visited` 위치 차이를 보도록 하자. 왜 이런 차이가 나오냐면 stack의 경우 방문할 '후보'를 넣는 것이다. 즉, 당장에 next로 방문할 것을 넣는게 아니라, '후보'를 넣기 때문에 방문했다는 표시를 달지 않는다. 반면에 재귀함수를 다음으로 방문할 값을 재귀함수로 바로 실행하는 개념이다. 따라서, `visited` 검사를 재귀함수 실행 직전에 하는 것이다.

### BFS
시작 노드를 queue에 넣고 방문 처리를 해준다.

1. queue에서 node를 pop한다.
2. node에 인접한 모든 node들 중 방문하지 않은 node를 queue에 넣고, 방문 처리한다.
3. queue가 빌 때까지 반복한다.

재밌는 것은 stack기반의 dfs를 사용할 때는, 방문 했는 지 안했는 지를 stack에서 pop할 때 했지만, bfs는 queue에 넣기 전에 방문 했는 지를 검사한다. 이러한 이유는 bfs는 바로 다음에 방문할 node를 queue에 넣는 것이고, stack기반 dfs는 다음에 방문할 node가 아니라 미래에 방문할 가능성이 있는 후보를 넣기 때문이다. 따라서, 바로 방문하지 않으니 방문 처리를 해주지 않는 것이다.

```py
def bfs(n, start, graph):
    visited = [False for _ in range(n+1)]
    q = deque()
    q.append(start)
    visited[start] = True
    
    while q:
        cur = q.popleft()
        print(cur, end=" ")
        for node in graph[cur]:
            if visited[node]:
                continue
            visited[node] = True
            q.append(node)
```

### DFS와 BFS의 차이
1. DFS는 깊이 찔러 들어가는 동작
2. BFS는 가중치가 같다는 가정하에 최단 경로를 보장

따라서, 최적의 해를 뽑는 경우의 수 문제는 DFS가 많이 나오고, 최단 경로 문제는 BFS가 많이 나온다.

## 다익스트라
BFS에서 간선의 가중치가 모두 같다는 가정 하에서 start노드에서 목적지까지의 최단 경로를 보장한다는 말은 사실, 간선의 가중치가 모두 같다면 간선의 갯수가 최하로 나오는게 최단 경로이기 때문이다. 그러나, 간선에 가중치가 다른 경우는 다르다. 이 경우는 간선의 갯수를 최하로 가는 경로가 최단 경로가 아니라, 그냥 가중치 값이 작은게 최단 경로이다. 

다익스트라는 가중치가 있는 간선에서 start노드부터 전체 노드의 최단 거리를 계산해준다.

다익스트라의 아이디어는 간단하다.
1. 현재 내가 알고있는 node들 중에 방문 하지 않은 node로 갈 때, 최단 거리로 갈 수 있는 node로 간다. (greedy)
2. A에서 방문 하지 않은 B node로 갈 때는 A로 가는 최단 거리를 이용해 B로 가는 최단 거리를 계산한다. (dp)

정리하자면, 내가 알고있는 최단 거리가 있고, 방문 하지 않은 곳 중에 최단 거리로 갈 수 있는 곳으로 가면서 각 노드마다의 최단 거리를 계산해주면, 그 결과는 최단 거리이다. 라는 것이다.

구현 방법은 다음과 같다.
1. start노드에서부터 각 노드에 대한 최단 거리를 기록하는 `dist` 배열과, 각 노드를 방문했다는 `check`배열을 만들어준다. 
2. 이때 `dist` 배열은 최단 거리 값을 기록해야하므로, 초기값 자체를 가장 큰 값으로 설정해준다.
3. start node를 방문해주고, start node에서 방문 하지 않은 node중 가장 최단 거리로 갈 수 있는, 방문하지 않은 node로 가도록 한다. 
4. dist배열과 check배열을 갱신해준다.
5. 방문 하지 않은 node 중에 최단 거리로 갈 수 있는 node로 방문한다.
6. 방문 하지 않은 node가 없을 때까지 반복한다.

이때, 방문하지 않은 node 중에 가장 최단 거리로 갈 수 있는 node를 고를 때, 최소힙을 사용한다. 만약 최소힙을 사용하지 않고 최단 거리를 검사하는 것은 N개의 node를 목적지로 삼고 start부터 목적지까지의 간선을 모두 check해서 최단 거리를 구하는 것과 같다. 따라서 O(N^2)가 나오는데, 최소힙을 쓰면 모든 간선마다 실행되므로 간선이 E라면, O(ElogN)이다. 

따라서, 다익스트라는 O(ElogN) 시간 복잡도를 가진다.

- dijkstra.py
```py
import heapq
# n은 node수, m은 간선 수, start는 시작 노드, graph는 연결된 관계
def dijkstra(n, m, start,graph):
    dist = [MAX for _ in range(n + 1)]
    check = [False for _ in range(n + 1)]
    heap = [(0,start)]
    dist[start] = 0
    
    while heap:
        _, cur = heapq.heappop(heap)
        if check[cur]: 
            continue
        
        check[cur] = True
        
        for weight, node in graph[cur]:
            next_dist = weight + dist[cur]
            if next_dist < dist[node]:
                dist[node] = next_dist
            heapq.heappush(heap, (dist[node], node))
```
여기서 중요한 점은 `if check[cur]`과 `check[cur]`이다. `bfs`와 달리 최소힙에서 원소를 뽑은 뒤에 `check`처리를 해주는 모습인데, 이는 dfs를 stack으로 구현한 것과 마찬가지로, 다익스트라 알고리즘은 heap에 다음에 최소가 될 후보를 넣기 때문이다. 

즉, 같은 node에 대해서 최소힙에 여러 개 있을 수 있다. 이는 현재 알고있는 node들을 통해 해당 node에 대한 최소 경로가 나중에 다른 node를 알게 될 때 더 최소로 갈 수 있기 때문에 최소힙에 넣을 때 check처리를 해주지 않은 것이다. 따라서, 최소힙에서 빼내게되면 해당 node는 이제 최단 경로를 얻었기 때문에 check처리를 해주는 것이다.

## 벨만 포드
https://www.youtube.com/watch?v=PIT-aYPPPIQ
https://www.youtube.com/watch?v=061eXyAFRuI

다익스트라는 시작점에서 모든 목적지에 대한 최단 거리를 계산해준다. 단, 이는 가중치가 양수인 경우만 가능한데, 음수인 경우는 불가능하다. 더 정확히 말하자면 음수만 있는 단방향 경로는 문제가 안되지만, 사이클이 있는 경우가 문제이다.

사이클이 있는 경우 음수가 더 큰 경우 음수만 반복해서 들어가는 것이 훨씬 이득이기 때문이다.
```               -----
s --2--> e --3--> | f |--7--> g
         |        -----
         |          |
        -6 -----------
```
1. s -> e -> f -> g로 가는 것은 2 + 3 + 7 = 12이지만  
2. s -> e -> f -> e록 가면 2 + 3 -6 = -1이 된다. 따라서 f -> e로 계속 무한 반복하게 된다.

만약, e ---> f 로 가는 가중치가 -6보다 절댓값으로 크거나 같으면 이런 일이 발생하지 않을 것이다. 그러나 지금과 같이 작은 경우에 문제가 발생한다. 이러한 문제를 해결하기 위해서는 회피를 해주어야 하는 것이다.

정리하면 다음과 같다.

1. 음의 간선이 문제가 되는가?? --> 아니다.
2. 음수 순환이 문제가 되는가?? --> 그렇지만, 모든 음수 순환이 문제가 되는 것은 아니다.
3. 시작점에서 목적지에 갈 떄, 그 경로에 존재하는 음수 순환이 문제가 되는가? --> 그렇다. 특히, 사이클에서 음수가 더 클 때가 문제가 된다. 

따라서, 벨만 포드 알고리즘은 다음과 같은 경우에 많이 사용된다.
1. 음수 가중치 edge가 있을 때 최단 거리를 구하기 위해 사용
2. 전체 그래프에서 음수 사이클의 존재 여부를 판단하기 위해서 사용

보통 코딩테스트에서는 음수 사이클의 존재 여부를 판단하기 위해서 많이 사용된다. 

최단경로는 **출발점으로부터 도달 가능하며, 음의 값을 가지는 사이클(순환)이 없는 경우**이다. 즉 정리하면 다음과 같다.
1. 최단 경로는 사이클(순환)을 포함해서는 안된다.
2. 최단 경로의 길이는 노드 개수 |V|에 대한, 최대 |V| - 1 이다. 왜냐면 순환이 없기 때문이다. 

다익스트라와 벨만 포드 알고리즘의 구현 상의 가장 큰 차이는, 다익스트라는 **노드 기준**이고 벨만포드는 **간선 기준**이다. 따라서 graph를 edge list로 구현한다. 

가령 1에서 2로 가는 edge의 가중치가 8이고, 2에서 5로 가는 edge가 5이면 다음과 같이 쓸 수 있다.
```py
edge_list = [(1,2,8) , (2,5,5)]
```

- 벨만 포드 알고리즘  
1. 초기화: 각 node에 최단거리 list를 만든다. 이때 start node는 0이고 나머지는 무한대로 넣는다.
```py
start = 1
n = 10
dist_list = [INF for _ in range(n)]
dist_list[start] = 0
``` 

2. 모든 edge를 확인해 최단거리 list 업데이트하기: 최단 거리 리스트에서 업데이트 반복 횟수는 node - 1이다. 왜냐하면 사이클 없이 최단거리를 만들기 위해서는 최대 n - 1개의 edge만 방문하면 된다.
```py
dist_list[end] = min(dist_list[start] + weight, dist_list[end])
```
만약 `dist_list[start]`가 `INF`라면 의미가 없기 때문에 업데이트를 해주지 않는다.

3. 업데이트: 목적지에 대한 최단 거리 업데이트를 실행한다. 단, 업데이트 반복 횟수가 k번이라면 해당 시점에 최단거리 list의 값은 시작점에서 k개의 에지를 사용했을 때 각 노드에 대한 최단 거리이다. 

| edge | 1 | 2 | 3| 4 | 5 | 6 |
|------|---|---|---|---|---|---|
|start| 1  | 2| 1 | 3| 4| 5 |
|end  | 2  | 5| 3| 4| 2 | 4| 
|weight| 8 | 5| 3 | 7| -4 | -2 |

- 최단 dist list    

| 1 | 2 | 3 | 4 | 5 |
|---|---|---|---|---|
|0| INF| INF| INF | INF |

다음의 경우 모든 edge를 보면서 update가 시작되는데, INF인 친구들은 넘어가므로 start node인 1과 연결된 edge만 본다. 다음과 같이 업데이트 된다. 

| 1 | 2 | 3 | 4 | 5 |
|---|---|---|---|---|
|0| 8| 3| INF | INF |

2와 3이 업데이트 된 이유는 start node인 1과 edge가 1개 이기 때문이다. 따라서, 1번째 업데이트는 start로부터 edge가 1개인 경우이다. 이는 업데이트 횟수가 k번이라면 해당 시점에 최단 거리 list의 값이 k개의 엣지를 사용했을 때 각 노드에 대한 최단 거리라는 것을 의미한다.

다음 2번째 update로 edge를 모두 검색한다. 이때 2, 3이 대상이다. 

| 1 | 2 | 3 | 4 | 5 |
|---|---|---|---|---|
|0| 8| 3| 10 | 13 |

3번째는 다음과 같다.

| 1 | 2 | 3 | 4 | 5 |
|---|---|---|---|---|
|0| 6| 3| 10 | 13 |

4번째는 다음과 같다.

| 1 | 2 | 3 | 4 | 5 |
|---|---|---|---|---|
|0| 6| 3| 10 | 11 |

음수 사이클이 없다면 4번만에 끝난다. 

이렇게 node의 갯수가 N개라면 N-1번 업데이트를 실행해주면 된다. 그러면 N-1번 업데이트를 실행해준 `dist_list`가 최단 거리 완성이다. 

그런데 이는 음수 사이클이 없을 때이기 때문에 n-1번만에 끝나는 것이다. 이렇게 완성된 후에 마지막으로 이 그래프에 음수 사이클에 존재하는 지 확인해야한다.

음수 사이클을 찾는 방법은 매우 간단한데, 모든 에지를 한 번씩 다시 사용해 업데이트되는 노드가 발생하는 지 확인한다. 만약 업데이트되는 노드가 있다면 음수 사이클이 된다는 것이다. 이는 N-1번 보다 더 최단 거리가 있다는 것이다. 이는 음수 사이클이 있다는 것이다.

5번째 돌리면 다음과 같다.

| 1 | 2 | 3 | 4 | 5 |
|---|---|---|---|---|
|0| 6| 3| 9 | 11 |

`dist_list[4]`가 바뀌었다. 이는 음수 사이클이 생겼다는 것이다.

벨만 포드 알고리즘에서는 음수 사이클이 생기면, 더 이상 경로를 찾을 수 없으므로 최단거리를 찾을 수 없다는 결론을 낸다. 

따라서, 모든 node개수가 V개라고 할 때, |V-1|번에 대해서 edge list를 모두 순회하므로 edge의 수가 E라면 O(VE)가 걸린다.

## 플루이드 워셜
그래프에서 최단 거리를 구하는 알고리즘이지만, **재밌게도 모든 노드 간에 최단 거리를 구하는 알고리즘이다**. 즉 시작점이 따로 있는 것이 아니다. 또한, 음수 가중치 에지가 있어도 수행할 수 있지만, 싸이클이 있으면 안된다.

- 동적 계획법의 원리를 이용해 알고리즘에 접근
- O(V^3)

핵심 원리는 굉장히 간단하다. 3중 for문으로 이루어질 정도로 코드도 간단한데, 다음과 같다.

A -> B까지의 최단 경로를 구했다고 할 때, 해당 최단 경로 중에서 K노드가 존재한다면, A -> K로 가는 부분 경로 역시 최단 경로이다. 

```
A --> C --> K --> B
```
위의 A ~ B까지의 경로가 최단 경로라면, `A --> C --> K`도 최단 경로라는 것이다.

왜냐하면 `A --> ~~ --> K`라는 어떠한 최단 경로가 또 다로 존재하면 그것이 `A ~ B` 최단 경로에 이미 포함이 되어있었어야 한다.

즉, 서울에서 지하철 타고 용산가서 KTX로 부산가는게 최단 경로라면, 서울에서 버스타고 용산가는게 더 최단 경로일 수는 없다는 것이다. 그렇다면 서울에서 버스타고 용산가서 KTX타고 부산가는게 더 빠르다는 것이다.

이 원리를 이용해서 다음과 같은 점화식을 세울 수 있다.
```py
D[S][E] = min(D[S][E], D[S][K] + D[K][E])
```
이 K를 부르트 포스로 모두 찾아보는 것이다.

- 구현
1. 최단 거리 list `D[S][E]`를 만들어준다. 단, 이때 S와 E가 자기 자신인 경우는 0이고 나머진 무한대로 넣어준다.
2. 최단 거리 list인 `D[S][E]`에 graph 정보를 업로드해준다.
3. 다음으로 점화식으로 최단 거리 list를 업데이트해준다. 이때 3중 for문 구조이다.

```
for 경유 K에 관해 1~N:
    for 출발 노드 S에 관해 1~N:
        for 도착 노드에 관해 1~N:
            D[s][e] = min(D[s][e], D[s][k] + D[k][e])
```

이렇게 동작하고 나면, 최단 거리가 나온다.